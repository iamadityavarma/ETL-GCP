# ğŸ”„ BigQuery ETL Workflow

## Complete Data Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CDC CHRONIC DISEASE DATA                       â”‚
â”‚                    https://data.cdc.gov (CSV API)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ HTTP GET Request
                                 â”‚ data_extractor.py
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          POSTGRESQL STAGING                             â”‚
â”‚                   staging.staging_cdc_chronic_disease                   â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Raw Data (As-is from API)                                      â”‚   â”‚
â”‚  â”‚ - Duplicates may exist                                         â”‚   â”‚
â”‚  â”‚ - Whitespace not cleaned                                       â”‚   â”‚
â”‚  â”‚ - No validation                                                â”‚   â”‚
â”‚  â”‚ - Metadata: loaded_at, load_date                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ SELECT * FROM staging
                                 â”‚ data_loader.py
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          SQL CLEANING LAYER                             â”‚
â”‚                         (PostgreSQL Functions)                          â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. Remove Duplicates (GROUP BY, HAVING COUNT(*) > 1)          â”‚   â”‚
â”‚  â”‚ 2. Trim Whitespace (TRIM on all TEXT columns)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ pd.read_sql (10K rows/chunk)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PANDAS CLEANING LAYER                           â”‚
â”‚                         (Python + pandas)                               â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. Date Formatting                                             â”‚   â”‚
â”‚  â”‚    - Parse 'date' columns â†’ datetime64[ns]                     â”‚   â”‚
â”‚  â”‚    - Handle invalid dates â†’ NaT                                â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚ 2. Null Handling                                               â”‚   â”‚
â”‚  â”‚    - Numbers â†’ fillna(0)                                       â”‚   â”‚
â”‚  â”‚    - Text â†’ fillna('Unknown')                                  â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚ 3. Text Standardization                                        â”‚   â”‚
â”‚  â”‚    - Convert to lowercase                                      â”‚   â”‚
â”‚  â”‚    - Strip extra whitespace                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ validate_data(df)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA VALIDATION LAYER                           â”‚
â”‚                       (Quality Checks + Logging)                        â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ âœ“ Logical Checks                                               â”‚   â”‚
â”‚  â”‚   - yearstart <= yearend                                       â”‚   â”‚
â”‚  â”‚   - datavalue in range [0, 100]                                â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚ âœ“ Null Checks                                                  â”‚   â”‚
â”‚  â”‚   - Critical fields: yearstart, yearend, locationabbr, topic   â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚ âœ“ Duplicate Detection                                          â”‚   â”‚
â”‚  â”‚   - Log count of duplicate rows                                â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚ âœ“ Anomaly Logging                                              â”‚   â”‚
â”‚  â”‚   - Save issues â†’ validation_issues_log.csv                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ pandas_gbq.to_gbq()
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            BIGQUERY TABLE                               â”‚
â”‚               {project}.{dataset}.cleaned_cdc_chronic_disease           â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Clean, Validated Data                                          â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚ âœ… No duplicates                                                â”‚   â”‚
â”‚  â”‚ âœ… Standardized text (lowercase, trimmed)                       â”‚   â”‚
â”‚  â”‚ âœ… Nulls handled (0 or 'unknown')                               â”‚   â”‚
â”‚  â”‚ âœ… Dates parsed correctly                                       â”‚   â”‚
â”‚  â”‚ âœ… Validated for logical consistency                            â”‚   â”‚
â”‚  â”‚ âœ… Schema auto-inferred from DataFrame                          â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚ Columns:                                                        â”‚   â”‚
â”‚  â”‚  - yearstart (INTEGER)                                         â”‚   â”‚
â”‚  â”‚  - yearend (INTEGER)                                           â”‚   â”‚
â”‚  â”‚  - locationabbr (STRING)                                       â”‚   â”‚
â”‚  â”‚  - locationdesc (STRING)                                       â”‚   â”‚
â”‚  â”‚  - topic (STRING)                                              â”‚   â”‚
â”‚  â”‚  - question (STRING)                                           â”‚   â”‚
â”‚  â”‚  - datavalue (FLOAT)                                           â”‚   â”‚
â”‚  â”‚  - stratification1 (STRING)                                    â”‚   â”‚
â”‚  â”‚  - ... (all CDC columns)                                       â”‚   â”‚
â”‚  â”‚  - loaded_at (TIMESTAMP)                                       â”‚   â”‚
â”‚  â”‚  - load_date (DATE)                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ Query & Analysis
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA CONSUMERS                                  â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   BI Tools       â”‚  â”‚  Data Science    â”‚  â”‚   Analysts       â”‚     â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚                  â”‚     â”‚
â”‚  â”‚  â€¢ Looker Studio â”‚  â”‚  â€¢ Notebooks     â”‚  â”‚  â€¢ SQL Queries   â”‚     â”‚
â”‚  â”‚  â€¢ Tableau       â”‚  â”‚  â€¢ Python/R      â”‚  â”‚  â€¢ Reports       â”‚     â”‚
â”‚  â”‚  â€¢ Power BI      â”‚  â”‚  â€¢ ML Models     â”‚  â”‚  â€¢ Dashboards    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technical Implementation

### Files & Responsibilities

```
data_extractor.py (Lines 1-423)
â”œâ”€â”€ APIExtractor class
â”‚   â”œâ”€â”€ extract_cdc_data()          â†’ Fetch CSV from CDC API
â”‚   â””â”€â”€ _create_session()           â†’ HTTP retry logic
â”‚
â””â”€â”€ PostgreSQLLoader class
    â”œâ”€â”€ create_staging_table()      â†’ CREATE/TRUNCATE table
    â”œâ”€â”€ load_data()                 â†’ Bulk INSERT with chunking
    â””â”€â”€ schema_matches()            â†’ Check if schema changed

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

data_loader.py (Lines 1-397)
â”œâ”€â”€ PostgreSQLConnector class
â”‚   â”œâ”€â”€ connect()                   â†’ Connect to PostgreSQL
â”‚   â””â”€â”€ fetch_data()                â†’ SELECT * FROM staging
â”‚
â”œâ”€â”€ SchemaValidator class
â”‚   â”œâ”€â”€ infer_schema()              â†’ Map pandas â†’ PostgreSQL types
â”‚   â””â”€â”€ validate_existing_table()   â†’ Check schema compatibility
â”‚
â”œâ”€â”€ PostgreSQLLoader class
â”‚   â””â”€â”€ create_staging_table()      â†’ Smart table creation/truncation
â”‚
â”œâ”€â”€ BigQueryWriter class â­
â”‚   â””â”€â”€ write()                     â†’ pandas_gbq.to_gbq()
â”‚       â”œâ”€â”€ if_exists='replace'     â†’ First chunk (create table)
â”‚       â””â”€â”€ if_exists='append'      â†’ Subsequent chunks (add data)
â”‚
â”œâ”€â”€ clean_and_normalize_sql()       â†’ SQL-level cleaning
â”œâ”€â”€ pandas_cleaning()               â†’ DataFrame-level cleaning
â””â”€â”€ validate_data()                 â†’ Quality checks + anomaly logging
```

---

## ğŸ“Š Data Transformation Examples

### Example 1: Text Standardization

**Before (Raw API Data):**
```
locationdesc: "  California  "
topic: "CANCER  "
```

**After (BigQuery):**
```
locationdesc: "california"
topic: "cancer"
```

### Example 2: Null Handling

**Before (Raw API Data):**
```
datavalue: NaN
stratification1: NaN
```

**After (BigQuery):**
```
datavalue: 0.0
stratification1: "unknown"
```

### Example 3: Date Parsing

**Before (Raw API Data):**
```
yearstart: "2020"  (TEXT)
yearend: "2021"    (TEXT)
```

**After (BigQuery):**
```
yearstart: 2020    (INTEGER)
yearend: 2021      (INTEGER)
```

---

## âš¡ Performance Characteristics

### Chunked Processing

```
Total Rows: 124,875
Chunk Size: 10,000

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1:  Rows 1-10,000    (REPLACE)   â”‚  â† Creates table
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 2:  Rows 10,001-20,000 (APPEND)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 3:  Rows 20,001-30,000 (APPEND)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ...                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 13: Rows 120,001-124,875 (APPEND)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Time Estimate:
- 10K rows â†’ ~10-15 seconds per chunk
- 125K rows â†’ ~2-3 minutes total
```

### Resource Usage

| Stage | Memory | CPU | Network |
|-------|--------|-----|---------|
| Extract (API) | Low (streaming) | Low | High (download) |
| SQL Clean | Database RAM | Database CPU | Low |
| Pandas Clean | ~chunk_size Ã— row_size | Medium | Low |
| BQ Upload | Low (pandas-gbq handles) | Low | High (upload) |

---

## ğŸ¯ Configuration Options

### Adjust Chunk Size

```python
# data_loader.py, line 365
chunk_size = 10000  # Default

# Options:
chunk_size = 5000   # Slower, less memory
chunk_size = 20000  # Faster, more memory
chunk_size = 1000   # For testing
```

### Change Load Behavior

```python
# data_loader.py, lines 379-383

# Option 1: Always replace table (fresh start)
bq_writer.write(df_valid, if_exists='replace')

# Option 2: Always append (incremental load)
bq_writer.write(df_valid, if_exists='append')

# Option 3: Current behavior (replace first, append rest)
if first_chunk:
    bq_writer.write(df_valid, if_exists='replace')
else:
    bq_writer.write(df_valid, if_exists='append')
```

### Modify Validation Rules

```python
# data_loader.py, lines 292-341

# Example: Add custom validation
if 'age' in df.columns:
    invalid_age = df[(df['age'] < 0) | (df['age'] > 120)]
    if not invalid_age.empty:
        issues.append(f"{len(invalid_age)} rows have invalid age")
```

---

## ğŸ“ˆ Monitoring Points

### Key Metrics to Track

```python
# In data_loader.py main() function:

1. Total rows processed       â†’ logger.info(f"Total rows: {total_rows}")
2. Chunk processing time       â†’ Track time per chunk
3. Validation issues           â†’ Count of issues logged
4. BigQuery write success      â†’ Check for exceptions
5. Final row count in BQ       â†’ Query after load
```

### Example Query to Verify Load

```sql
-- Check if data loaded correctly
SELECT 
    COUNT(*) as total_rows,
    MIN(yearstart) as min_year,
    MAX(yearend) as max_year,
    COUNT(DISTINCT locationabbr) as unique_states,
    COUNT(DISTINCT topic) as unique_topics,
    MAX(loaded_at) as last_load_time
FROM `your-project.your_dataset.cleaned_cdc_chronic_disease`
```

---

## ğŸ”„ Scheduling Options

### Option 1: Cron (Linux/Mac)
```bash
# Daily at 2 AM
0 2 * * * cd /path/to/GCP-ETL && python data_loader.py >> logs/loader.log 2>&1
```

### Option 2: Task Scheduler (Windows)
```
1. Open Task Scheduler
2. Create Basic Task
3. Trigger: Daily at 2:00 AM
4. Action: Start Program
   - Program: C:\path\to\python.exe
   - Arguments: data_loader.py
   - Start in: C:\path\to\GCP-ETL
```

### Option 3: Cloud Scheduler (GCP)
```bash
gcloud scheduler jobs create http etl-daily \
    --schedule="0 2 * * *" \
    --uri="https://your-cloud-run-url/run" \
    --http-method=POST
```

---

## ğŸ“ Next Steps

### Immediate
1. âœ… Run `test_bigquery_connection.py`
2. âœ… Run full pipeline: `data_extractor.py` â†’ `data_loader.py`
3. âœ… Verify data in BigQuery Console

### Short Term
4. âœ… Create visualizations (Looker Studio, Tableau)
5. âœ… Set up scheduled runs (cron/scheduler)
6. âœ… Add monitoring/alerting

### Long Term
7. âœ… Optimize with partitioning/clustering
8. âœ… Add incremental load logic
9. âœ… Create data quality dashboard

---

**Pipeline Ready! ğŸš€** See `SETUP_SUMMARY.md` for quick start guide.

